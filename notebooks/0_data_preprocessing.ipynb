{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/init_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import config\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spider_dataset(dataset_path: str, tables_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Loads and parses the Spider dataset from the given path.\n",
    "    \n",
    "    :param dataset_path: Path to the Spider dataset folder.\n",
    "    :return: A list of dictionaries containing NL questions, SQL queries, and schema metadata.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(dataset_path), 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    with open(os.path.join(tables_path), 'r', encoding='utf-8') as f:\n",
    "        tables_data = json.load(f)\n",
    "    \n",
    "    # Map database schemas\n",
    "    schema_map = {table[\"db_id\"]: table for table in tables_data}\n",
    "    \n",
    "    parsed_data = []\n",
    "    \n",
    "    for item in train_data:\n",
    "        db_id = item[\"db_id\"]\n",
    "        schema = schema_map.get(db_id, {})\n",
    "        parsed_data.append({\n",
    "            \"db_id\": db_id,\n",
    "            \"question\": item[\"question\"],\n",
    "            \"query\": item[\"query\"],\n",
    "            \"schema\": schema\n",
    "        })\n",
    "    \n",
    "    return parsed_data\n",
    "\n",
    "\n",
    "def format_for_model(parsed_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Formats the parsed Spider dataset into a structured format as per the requested output.\n",
    "    \n",
    "    :param parsed_data: List of parsed Spider dataset entries.\n",
    "    :return: A list of formatted dictionaries.\n",
    "    \"\"\"\n",
    "    formatted_data = []\n",
    "    \n",
    "    for idx, entry in enumerate(parsed_data):\n",
    "        db_id = entry[\"db_id\"]\n",
    "        table_names = entry[\"schema\"].get(\"table_names_original\", [])\n",
    "        columns = entry[\"schema\"].get(\"column_names_original\", [])\n",
    "        foreign_keys = entry[\"schema\"].get(\"foreign_keys\", [])\n",
    "        column_idx_map = {\n",
    "            idx: (table_names[table_idx], col_name)\n",
    "            for idx, (table_idx, col_name) in enumerate(columns)\n",
    "            if table_idx >= 0\n",
    "        }\n",
    "        \n",
    "        # Generate simplified DDL\n",
    "        simplified_ddl = \"\\n\".join(\n",
    "            [f\"{table}({', '.join(col for i, col in columns if i == tid)})\" for tid, table in enumerate(table_names)]\n",
    "        )\n",
    "        \n",
    "        # Generate full DDL\n",
    "        full_ddl_statements = []\n",
    "        for tid, table in enumerate(table_names):\n",
    "            table_columns = [col for i, col in columns if i == tid]\n",
    "            col_definitions = \", \".join([f\"{col} TEXT\" for col in table_columns])\n",
    "            full_ddl_statements.append(f\"CREATE TABLE {table}({col_definitions});\")\n",
    "        \n",
    "        full_ddl = \"\\n\\n\".join(full_ddl_statements)\n",
    "        \n",
    "        # Foreign keys with correct mapping\n",
    "        foreign_key_constraints = []\n",
    "        for fk in foreign_keys:\n",
    "            if len(fk) == 2 and fk[0] in column_idx_map and fk[1] in column_idx_map:\n",
    "                child_table, child_column = column_idx_map[fk[0]]\n",
    "                parent_table, parent_column = column_idx_map[fk[1]]\n",
    "                fk_constraint = f\"{child_table}({child_column}) REFERENCES {parent_table}({parent_column})\"\n",
    "                foreign_key_constraints.append(fk_constraint)\n",
    "        \n",
    "        formatted_data.append({\n",
    "            \"id\": idx,\n",
    "            \"db\": db_id,\n",
    "            \"question\": entry[\"question\"],\n",
    "            \"gold_sql\": entry[\"query\"],\n",
    "            \"simplified_ddl\": simplified_ddl,\n",
    "            \"full_ddl\": full_ddl,\n",
    "            \"foreign_key\": foreign_key_constraints\n",
    "        })\n",
    "    \n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = config.SPIDER_DATA_DIR\n",
    "datasets = {\n",
    "    'train': {\n",
    "        'data': 'train_spider',\n",
    "        'tables': 'tables'\n",
    "    }, \n",
    "    'dev': {\n",
    "        'data': 'dev',\n",
    "        'tables': 'tables'\n",
    "    },\n",
    "    'test': {\n",
    "        'data': 'test',\n",
    "        'tables': 'test_tables'\n",
    "    } \n",
    "}\n",
    "\n",
    "for partition, dataset in datasets.items():\n",
    "    parsed_data = load_spider_dataset(\n",
    "        os.path.join(dataset_path, dataset['data']+'.json'),\n",
    "        os.path.join(dataset_path, dataset['tables']+'.json')\n",
    "    )\n",
    "    formatted_data = format_for_model(parsed_data)\n",
    "\n",
    "    # Save output\n",
    "    with open(os.path.join(config.DATA_DIR,partition+'.json'), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(formatted_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unrc-cs-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
